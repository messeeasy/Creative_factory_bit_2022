{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "li7DvRTBW3D6"
      },
      "source": [
        "## **Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "colab_type": "code",
        "id": "JAGmKzcQvETi",
        "outputId": "22960d60-7d29-4d2d-8d7a-2ddb70d87fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5869 sha256=49de3fa8d7726b32250266c5f659ebb2db98f0ce04e2cc1ed81d63b32eb90ba7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/60/87/28af2605138deac93d162904df42b6fdda1dab9b8757c62aa3\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gOD04lwoha8j"
      },
      "outputs": [],
      "source": [
        "#  os and argparse is done to read files from local folders\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import scipy.signal\n",
        "from python_speech_features import mfcc\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "# tesorflow is for the Deep learning model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense ,LSTM , TimeDistributed\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "import IPython\n",
        "import librosa\n",
        "from scipy.signal import butter, lfilter\n",
        "%matplotlib inline\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "colab_type": "code",
        "id": "E6WKgvf-vCf4",
        "outputId": "7d80ee36-5be4-41d4-884f-ed066289e627"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive  # the sounds are stored in google drive \n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "8S1jwaxpvPQO",
        "outputId": "c199afdf-c1c7-43e0-8ab8-6880ea346fb4"
      },
      "outputs": [],
      "source": [
        "# folder where files are stored\n",
        "#cd /content/gdrive/'My Drive'/Colab Notebooks/data/training-a   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e0hJIGbCX002"
      },
      "source": [
        "**about the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "CRrgF44PvZxe",
        "outputId": "7636aaaa-2eb2-4afb-a468-a5fa60a53a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/Creative_factory_bit_2022/LSTM_demo\n",
            "MFCC EXTRACTION DONE !\n"
          ]
        }
      ],
      "source": [
        "#############################################################  MFCC EXTRACTION   ##########################################################\n",
        "# Variable assignment \n",
        "tt = 0\n",
        "time_steps = 450\n",
        "data_directory=os.getcwd()\n",
        "print(data_directory)\n",
        "#data_directory='/workspaces/python_env1/Creative_factory/the-circor-digiscope-phonocardiogram-dataset-1.0.3/AV'\n",
        "#data_directory=dataset = '../dataset_heart_sound/AV'\n",
        "data_directory=dataset = '../dataset_heart_sound/AV'\n",
        "nfft = 1203 # Number of FFTs\n",
        "\n",
        "# What diff ?\n",
        "digit_directory = data_directory \n",
        "\n",
        "# To normalize the signal\n",
        "def normalize(v):\n",
        "    norm = np.linalg.norm(v)\n",
        "    if norm == 0: \n",
        "        return v\n",
        "    return v / norm\n",
        "    \n",
        "def process_directory():\n",
        "    mfcc_features = list()\n",
        "    \"\"\"\n",
        "    for filename in [x for x in os.listdir(data_directory) if x.endswith('.wav')]:\n",
        "        # Read the .wav input file\n",
        "        filepath = os.path.join(digit_directory, filename)\n",
        "        sampling_freq, audio = wavfile.read(filepath)\n",
        "        label=\"n.wav\"\n",
        "\n",
        "\n",
        "# open the .hea file of the same filename to get the label as normal /abnormal.\n",
        "        st= data_directory +\"/\"+filename.split(\".\")[0]+\".hea\"\n",
        "        with open(st,'r') as f:\n",
        "            for line in f:\n",
        "                for word in line.split():\n",
        "                    if(word==\"Abnormal\"):\n",
        "                        label=\"a.wav\"\n",
        "\"\"\"\n",
        "    #dataset = [{'sampling_freq', 'audio': wavfile.read(path) , 'label': path.split('/' )[6] } for path in glob.glob(\"/workspaces/python_env1/Creative_factory/the-circor-digiscope-phonocardiogram-dataset-1.0.3/AV/**/*.wav\")]\n",
        "    for path in glob.glob(\"../dataset_heart_sound/AV/**/*.wav\"):\n",
        "        sampling_freq, audio = wavfile.read(path)\n",
        "        label = path.split('/')[3]\n",
        "            \n",
        "# now we have the label stored in 'label' and the audio as 'audio' with sampling freq. as 'sampling_freq'.\n",
        "        #audio1 = audio[dic[filename.split(\".\")[0]]:]\n",
        "        #audio1 = SVDnoise(audio/32768)\n",
        "        audio1 = audio\n",
        "        temp = mfcc(audio1, sampling_freq, nfft=nfft)\n",
        "        temp = temp[tt:tt+time_steps,:]\n",
        "        mfcc_features.append({\"label\": label, \"mfcc\": temp })\n",
        "\n",
        "\n",
        "        # mfcc features of this audio has been appended to the list \n",
        "    return mfcc_features\n",
        "\n",
        "###########################   CREATING MFCC FEATURES   ############################\n",
        "processed_files = list()\n",
        "mfcc_features = process_directory()\n",
        "random.shuffle(mfcc_features)\n",
        "\n",
        "############   TRAINING DATA   ###########\n",
        "size = (8*len(mfcc_features))/10\n",
        "train_features = mfcc_features[0:int(size)]\n",
        "test_list = mfcc_features[int(size+1):]\n",
        "train_size = 0\n",
        "for feature in train_features:\n",
        "    train_size += 1\n",
        "    processed_files.append({'label': feature[\"label\"], 'feature': feature[\"mfcc\"] })\n",
        "# Train rnn for each MFCC and add to training set\n",
        "x_train = np.zeros((train_size, time_steps ,13))\n",
        "y_train = np.zeros((train_size))\n",
        "i = 0\n",
        "for processed_file in processed_files:\n",
        "#       print(processed_file['label'])\n",
        "#       print(processed_file['feature'].shape)\n",
        "    x_train[i,:,:] = processed_file['feature']\n",
        "    s = processed_file['label']\n",
        "    if(s[0]=='a'):\n",
        "        y_train[i]=1\n",
        "    else:\n",
        "        y_train[i]=0\n",
        "    i += 1\n",
        "normalize(x_train)\n",
        "\n",
        "############   TESTING DATA   #############\n",
        "test_files = list()\n",
        "test_features = test_list\n",
        "test_size = 0\n",
        "for feature in test_features:\n",
        "    test_size += 1\n",
        "    test_files.append({'label': feature[\"label\"], 'feature': feature[\"mfcc\"] })\n",
        "y_test = np.zeros((test_size))\n",
        "x_test = np.zeros((test_size, time_steps ,13))\n",
        "i = 0\n",
        "for test_file in test_files:\n",
        "    x_test[i,:,:] = test_file['feature']\n",
        "    s = test_file['label']\n",
        "#             print(s)\n",
        "    if(s[0]=='a'):\n",
        "        y_test[i]=1\n",
        "    else:\n",
        "        y_test[i]=0\n",
        "    i += 1\n",
        "normalize(x_test)\n",
        "print('MFCC EXTRACTION DONE !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(629, 450, 13)\n",
            "(157, 450, 13)\n",
            "(629,)\n",
            "(157,)\n",
            "[1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "86\n",
            "308\n",
            "787\n",
            "{'label': 'abnormal', 'mfcc': array([[ 17.25163153,  -7.47371584, -24.03596192, ...,  -4.92772153,\n",
            "         -4.4076607 ,  -5.58898588],\n",
            "       [ 13.21657076,  -9.4202569 ,  -9.92390891, ...,   3.89162192,\n",
            "         13.99063658,  -4.71266614],\n",
            "       [ 13.08747044,  -3.44597763,  -9.12435978, ...,  -4.39275704,\n",
            "         18.12731561,  -7.2472483 ],\n",
            "       ...,\n",
            "       [ 12.86160226,  -6.19358918, -13.12099989, ..., -18.16718332,\n",
            "          4.63782756,   4.927715  ],\n",
            "       [ 14.29347902,   9.17891663,  -0.8129442 , ...,  -6.36782269,\n",
            "         -1.67530702,   4.87401308],\n",
            "       [ 17.59708355,   8.5375249 , -28.97842435, ..., -17.25149456,\n",
            "          6.46490812,   1.42897308]])}\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_test)\n",
        "print(np.count_nonzero(y_test == 0))\n",
        "print(np.count_nonzero(y_train == 0))\n",
        "print(len(mfcc_features))\n",
        "print(mfcc_features[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZaT_R-l04RW"
      },
      "source": [
        "## RNN MODEL\n",
        "### Model Structure:\n",
        "- visible layer or input layer : size of input = 13 (mfcc matrix has column size 13)\n",
        "- hidden layer 1: LSTM layer\n",
        "- hidden layer 2: LSTM layer\n",
        "- 1 dense layer having activation function = \"relu\" (rectified linear)\n",
        "- output layer : classification  \n",
        "\n",
        "![download.png](attachment:download.png)  \n",
        "<font size=\"2\">*In the figure, the dense layer is missing, but this is to give a brief idea of how the data is flowing in the model structure.*</font>  \n",
        "### Building the Model:\n",
        "- loss function: to compute the loss (currently \"mean squared error\")\n",
        "- optimizer function: adam\n",
        "- metrics: accuracy\n",
        "- **model.fit:** this function tries for the best possible fit of the model to the training data.\n",
        "<br>\n",
        "<font size=\"2\"> <font color=\"brown\"> The later part of the code was to try the model for different values of Dopout(lmabda) to calculate accuracy.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RmDoZ-M-vZr_"
      },
      "outputs": [],
      "source": [
        "dropouts = np.array([0.15])\n",
        "accuracy = np.zeros(len(dropouts),dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "sMiXU1q1vZlt",
        "outputId": "2e53da3a-d7fe-4bf3-d914-1eec6ef3b2c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-03 22:41:24.557370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:24.652917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:24.653249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:24.655372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-03 22:41:24.658053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:24.658392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:24.658739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:26.487811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:26.488834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:26.488862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2022-09-03 22:41:26.489349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2022-09-03 22:41:26.489423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3949 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-03 22:41:32.546528: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 13s 76ms/step - loss: 0.2503 - accuracy: 0.5151\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2468 - accuracy: 0.5517\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.2417 - accuracy: 0.5930\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.2356 - accuracy: 0.6137\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.2303 - accuracy: 0.6328\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2253 - accuracy: 0.6534\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2152 - accuracy: 0.6709\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.2067 - accuracy: 0.6852\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 5s 72ms/step - loss: 0.1983 - accuracy: 0.7218\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1856 - accuracy: 0.7361\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1733 - accuracy: 0.7472\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1703 - accuracy: 0.7504\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.1543 - accuracy: 0.7870\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1423 - accuracy: 0.8013\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.1345 - accuracy: 0.8124\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1234 - accuracy: 0.8315\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.1124 - accuracy: 0.8442\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.1090 - accuracy: 0.8585\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1024 - accuracy: 0.8553\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.0989 - accuracy: 0.8792\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0889 - accuracy: 0.8887\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.0823 - accuracy: 0.8967\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 5s 87ms/step - loss: 0.0814 - accuracy: 0.8967\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0866 - accuracy: 0.8855\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.0785 - accuracy: 0.8998\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.0741 - accuracy: 0.9110\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 6s 88ms/step - loss: 0.0655 - accuracy: 0.9237\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 5s 85ms/step - loss: 0.0683 - accuracy: 0.9062\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.0629 - accuracy: 0.9189\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0636 - accuracy: 0.9300\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0706 - accuracy: 0.9205\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1069 - accuracy: 0.8569\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.0667 - accuracy: 0.9157\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0606 - accuracy: 0.9285\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.0601 - accuracy: 0.9237\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0477 - accuracy: 0.9380\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 5s 84ms/step - loss: 0.0780 - accuracy: 0.8983\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0568 - accuracy: 0.9316\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0821 - accuracy: 0.8903\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0513 - accuracy: 0.9396\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0375 - accuracy: 0.9603\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0441 - accuracy: 0.9475\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0391 - accuracy: 0.9571\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0348 - accuracy: 0.9618\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0375 - accuracy: 0.9603\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0508 - accuracy: 0.9348\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0378 - accuracy: 0.9603\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0502 - accuracy: 0.9444\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0364 - accuracy: 0.9587\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 4s 70ms/step - loss: 0.0318 - accuracy: 0.9666\n",
            "5/5 [==============================] - 1s 44ms/step\n",
            "[0.43128105998039246, 0.47770699858665466]\n"
          ]
        }
      ],
      "source": [
        "#########################  VARIABLES  ######################\n",
        "cell_no = 13\n",
        "Epoch_size = 50\n",
        "Lambda = 0.029  # dropout variable for regularization\n",
        "# No. of LSTM layers =2\n",
        "# Cost func. = cosh\n",
        "\n",
        "####################   MODEL STRUCTURE  ####################\n",
        "visible=Input(shape=(None,13))\n",
        "hidden11 = LSTM(cell_no,return_sequences=True)(visible)\n",
        "hidden1=Dropout(Lambda)(hidden11)\n",
        "\n",
        "hidden22 = LSTM(cell_no)(hidden1)\n",
        "hidden2=Dropout(Lambda)(hidden22)\n",
        "\n",
        "hidden33 = Dense(10, activation='relu')(hidden2)\n",
        "hidden3 = Dropout(Lambda)(hidden33)\n",
        "# hidden4 = TimeDistributed(Dense(1))\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(hidden3)\n",
        "# output=Dropout(Lambda)(output1)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "##################   MODEL END ########################\n",
        "count = 0\n",
        "for dr in dropouts:\n",
        "    total=0\n",
        "    for ii in range(1):\n",
        "        Lambda = dr\n",
        "        print(dr)\n",
        "\n",
        "        model.fit(x_train, y_train, epochs=Epoch_size, batch_size=10,verbose=1)\n",
        "        predict=model.predict(x_test)\n",
        "        y_pred=(predict>0.1)\n",
        "        acc=model.evaluate(x_test,y_test,verbose=0)\n",
        "        # print(predict)\n",
        "\n",
        "        total += acc[1]\n",
        "        print(acc)\n",
        "    total /=1\n",
        "    accuracy[count] = total\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "colab_type": "code",
        "id": "Z1WTvY0dyQHi",
        "outputId": "609008ca-38dc-4f8e-9abe-1b3a932d4a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5154458009618942\n",
            "0.5136750736980019\n",
            "0.4885149903088787\n",
            "[[29 57]\n",
            " [22 49]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Print f1, precision, and recall scores\n",
        "print(precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(f1_score(y_test, y_pred , average=\"macro\"))\n",
        "confusion = confusion_matrix(y_test,y_pred,labels=[0,1])\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "9qtXvBvWHt8a",
        "outputId": "7632fc5d-c7b3-4a10-c632-054b7a19fc34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.477707])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "loVX2KG6zems"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Heart Sound Classification Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "li7DvRTBW3D6"
      },
      "source": [
        "## **Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "colab_type": "code",
        "id": "JAGmKzcQvETi",
        "outputId": "22960d60-7d29-4d2d-8d7a-2ddb70d87fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.8/dist-packages (0.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gOD04lwoha8j"
      },
      "outputs": [],
      "source": [
        "#  os and argparse is done to read files from local folders\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import scipy.signal\n",
        "from python_speech_features import mfcc\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "# tesorflow is for the Deep learning model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense ,LSTM , TimeDistributed\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "import IPython\n",
        "import librosa\n",
        "from scipy.signal import butter, lfilter\n",
        "%matplotlib inline\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "colab_type": "code",
        "id": "E6WKgvf-vCf4",
        "outputId": "7d80ee36-5be4-41d4-884f-ed066289e627"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive  # the sounds are stored in google drive \n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "8S1jwaxpvPQO",
        "outputId": "c199afdf-c1c7-43e0-8ab8-6880ea346fb4"
      },
      "outputs": [],
      "source": [
        "# folder where files are stored\n",
        "#cd /content/gdrive/'My Drive'/Colab Notebooks/data/training-a   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e0hJIGbCX002"
      },
      "source": [
        "**about the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "CRrgF44PvZxe",
        "outputId": "7636aaaa-2eb2-4afb-a468-a5fa60a53a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/Creative_factory_bit_2022/LSTM_demo\n",
            "MFCC EXTRACTION DONE !\n"
          ]
        }
      ],
      "source": [
        "#############################################################  MFCC EXTRACTION   ##########################################################\n",
        "# Variable assignment \n",
        "tt = 0\n",
        "time_steps = 450\n",
        "data_directory=os.getcwd()\n",
        "print(data_directory)\n",
        "#data_directory='/workspaces/python_env1/Creative_factory/the-circor-digiscope-phonocardiogram-dataset-1.0.3/AV'\n",
        "#data_directory=dataset = '../dataset_heart_sound/AV'\n",
        "data_directory=dataset = '../dataset_heart_sound/AV'\n",
        "nfft = 1203 # Number of FFTs\n",
        "\n",
        "# What diff ?\n",
        "digit_directory = data_directory \n",
        "\n",
        "# To normalize the signal\n",
        "def normalize(v):\n",
        "    norm = np.linalg.norm(v)\n",
        "    if norm == 0: \n",
        "        return v\n",
        "    return v / norm\n",
        "    \n",
        "def process_directory():\n",
        "    mfcc_features = list()\n",
        "    \"\"\"\n",
        "    for filename in [x for x in os.listdir(data_directory) if x.endswith('.wav')]:\n",
        "        # Read the .wav input file\n",
        "        filepath = os.path.join(digit_directory, filename)\n",
        "        sampling_freq, audio = wavfile.read(filepath)\n",
        "        label=\"n.wav\"\n",
        "\n",
        "\n",
        "# open the .hea file of the same filename to get the label as normal /abnormal.\n",
        "        st= data_directory +\"/\"+filename.split(\".\")[0]+\".hea\"\n",
        "        with open(st,'r') as f:\n",
        "            for line in f:\n",
        "                for word in line.split():\n",
        "                    if(word==\"Abnormal\"):\n",
        "                        label=\"a.wav\"\n",
        "\"\"\"\n",
        "    #dataset = [{'sampling_freq', 'audio': wavfile.read(path) , 'label': path.split('/' )[6] } for path in glob.glob(\"/workspaces/python_env1/Creative_factory/the-circor-digiscope-phonocardiogram-dataset-1.0.3/AV/**/*.wav\")]\n",
        "    for path in glob.glob(\"../dataset_heart_sound/AV/**/*.wav\"):\n",
        "        sampling_freq, audio = wavfile.read(path)\n",
        "        label = path.split('/')[3]\n",
        "            \n",
        "# now we have the label stored in 'label' and the audio as 'audio' with sampling freq. as 'sampling_freq'.\n",
        "        #audio1 = audio[dic[filename.split(\".\")[0]]:]\n",
        "        #audio1 = SVDnoise(audio/32768)\n",
        "        audio1 = audio\n",
        "        temp = mfcc(audio1, sampling_freq, nfft=nfft)\n",
        "        temp = temp[tt:tt+time_steps,:]\n",
        "        mfcc_features.append({\"label\": label, \"mfcc\": temp })\n",
        "\n",
        "\n",
        "        # mfcc features of this audio has been appended to the list \n",
        "    return mfcc_features\n",
        "\n",
        "###########################   CREATING MFCC FEATURES   ############################\n",
        "processed_files = list()\n",
        "mfcc_features = process_directory()\n",
        "random.shuffle(mfcc_features)\n",
        "\n",
        "############   TRAINING DATA   ###########\n",
        "size = (8*len(mfcc_features))/10\n",
        "train_features = mfcc_features[0:int(size)]\n",
        "test_list = mfcc_features[int(size+1):]\n",
        "train_size = 0\n",
        "for feature in train_features:\n",
        "    train_size += 1\n",
        "    processed_files.append({'label': feature[\"label\"], 'feature': feature[\"mfcc\"] })\n",
        "# Train rnn for each MFCC and add to training set\n",
        "x_train = np.zeros((train_size, time_steps ,13))\n",
        "y_train = np.zeros((train_size))\n",
        "i = 0\n",
        "for processed_file in processed_files:\n",
        "#       print(processed_file['label'])\n",
        "#       print(processed_file['feature'].shape)\n",
        "    x_train[i,:,:] = processed_file['feature']\n",
        "    s = processed_file['label']\n",
        "    if(s[0]=='a'):\n",
        "        y_train[i]=1\n",
        "    else:\n",
        "        y_train[i]=0\n",
        "    i += 1\n",
        "normalize(x_train)\n",
        "\n",
        "############   TESTING DATA   #############\n",
        "test_files = list()\n",
        "test_features = test_list\n",
        "test_size = 0\n",
        "for feature in test_features:\n",
        "    test_size += 1\n",
        "    test_files.append({'label': feature[\"label\"], 'feature': feature[\"mfcc\"] })\n",
        "y_test = np.zeros((test_size))\n",
        "x_test = np.zeros((test_size, time_steps ,13))\n",
        "i = 0\n",
        "for test_file in test_files:\n",
        "    x_test[i,:,:] = test_file['feature']\n",
        "    s = test_file['label']\n",
        "#             print(s)\n",
        "    if(s[0]=='a'):\n",
        "        y_test[i]=1\n",
        "    else:\n",
        "        y_test[i]=0\n",
        "    i += 1\n",
        "normalize(x_test)\n",
        "print('MFCC EXTRACTION DONE !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(629, 450, 13)\n",
            "(157, 450, 13)\n",
            "(629,)\n",
            "(157,)\n",
            "[1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1.]\n",
            "80\n",
            "314\n",
            "787\n",
            "{'label': 'normal', 'mfcc': array([[ 18.94922505, -19.61940194,  -7.84488204, ...,  -2.70096884,\n",
            "         -0.20033944,  -1.30123459],\n",
            "       [ 16.57168818, -15.81586785,   3.56729346, ...,   6.1885533 ,\n",
            "         -1.57125911,   4.94157173],\n",
            "       [ 19.24671712, -22.79319255, -10.02837188, ...,  -7.43946962,\n",
            "         -1.15753791,  -3.39792213],\n",
            "       ...,\n",
            "       [ 15.58839344,  26.67785986,  10.23820998, ..., -13.45850704,\n",
            "          5.13085329,  -7.65847274],\n",
            "       [ 15.58947185,  28.75926997,   9.94111382, ..., -12.44775494,\n",
            "          8.44294096, -16.11258716],\n",
            "       [ 13.4098012 ,  13.98333944,   2.39577333, ...,   0.39994992,\n",
            "         -4.00510499,  -1.82603156]])}\n",
            "450\n",
            "13\n",
            "13\n"
          ]
        }
      ],
      "source": [
        "# input size\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_test)\n",
        "print(np.count_nonzero(y_test == 0))\n",
        "print(np.count_nonzero(y_train == 0))\n",
        "print(len(mfcc_features))\n",
        "print(mfcc_features[1])\n",
        "print(len(mfcc_features[1]['mfcc']))\n",
        "print(len(mfcc_features[1]['mfcc'][1]))\n",
        "print(len(x_train[1][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZaT_R-l04RW"
      },
      "source": [
        "## RNN MODEL\n",
        "### Model Structure:\n",
        "- visible layer or input layer : size of input = 13 (mfcc matrix has column size 13)\n",
        "- hidden layer 1: LSTM layer\n",
        "- hidden layer 2: LSTM layer\n",
        "- 1 dense layer having activation function = \"relu\" (rectified linear)\n",
        "- output layer : classification  \n",
        "\n",
        "![download.png](attachment:download.png)  \n",
        "<font size=\"2\">*In the figure, the dense layer is missing, but this is to give a brief idea of how the data is flowing in the model structure.*</font>  \n",
        "### Building the Model:\n",
        "- loss function: to compute the loss (currently \"mean squared error\")\n",
        "- optimizer function: adam\n",
        "- metrics: accuracy\n",
        "- **model.fit:** this function tries for the best possible fit of the model to the training data.\n",
        "<br>\n",
        "<font size=\"2\"> <font color=\"brown\"> The later part of the code was to try the model for different values of Dopout(lmabda) to calculate accuracy.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RmDoZ-M-vZr_"
      },
      "outputs": [],
      "source": [
        "dropouts = np.array([0.15])\n",
        "accuracy = np.zeros(len(dropouts),dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "sMiXU1q1vZlt",
        "outputId": "2e53da3a-d7fe-4bf3-d914-1eec6ef3b2c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 12s 92ms/step - loss: 0.2522 - accuracy: 0.4897\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.2452 - accuracy: 0.5628\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.2405 - accuracy: 0.5771\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.2358 - accuracy: 0.6089\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.2268 - accuracy: 0.6216\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 8s 121ms/step - loss: 0.2194 - accuracy: 0.6804\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.2110 - accuracy: 0.6725\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 6s 98ms/step - loss: 0.2003 - accuracy: 0.6916\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.1875 - accuracy: 0.7409\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 8s 134ms/step - loss: 0.1796 - accuracy: 0.7440\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 9s 140ms/step - loss: 0.1852 - accuracy: 0.7345\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.1629 - accuracy: 0.7742\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.1548 - accuracy: 0.7949\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 5s 87ms/step - loss: 0.1515 - accuracy: 0.7933\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.1393 - accuracy: 0.8108\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.1301 - accuracy: 0.8347\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.1359 - accuracy: 0.8188\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 6s 95ms/step - loss: 0.1258 - accuracy: 0.8235\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.1175 - accuracy: 0.8490\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 6s 88ms/step - loss: 0.1202 - accuracy: 0.8315\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.1007 - accuracy: 0.8744\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0909 - accuracy: 0.8998\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 5s 87ms/step - loss: 0.0790 - accuracy: 0.9078\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0821 - accuracy: 0.9062\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0703 - accuracy: 0.9205\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.0732 - accuracy: 0.9173\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 5s 84ms/step - loss: 0.0706 - accuracy: 0.9269\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.0644 - accuracy: 0.9221\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.0786 - accuracy: 0.9030\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.0650 - accuracy: 0.9269\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.0661 - accuracy: 0.9269\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.0716 - accuracy: 0.9141\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 6s 88ms/step - loss: 0.0716 - accuracy: 0.9126\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0567 - accuracy: 0.9380\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 6s 97ms/step - loss: 0.0557 - accuracy: 0.9428\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 5s 86ms/step - loss: 0.0672 - accuracy: 0.9189\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.0540 - accuracy: 0.9348\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.0480 - accuracy: 0.9444\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.0337 - accuracy: 0.9666\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0345 - accuracy: 0.9698\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0301 - accuracy: 0.9714\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.0249 - accuracy: 0.9777\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0242 - accuracy: 0.9730\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.0361 - accuracy: 0.9587\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0323 - accuracy: 0.9650\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 5s 85ms/step - loss: 0.0231 - accuracy: 0.9777\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.0375 - accuracy: 0.9539\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.0524 - accuracy: 0.9348\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.0382 - accuracy: 0.9539\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.0383 - accuracy: 0.9507\n",
            "5/5 [==============================] - 6s 56ms/step\n",
            "[0.4176282584667206, 0.5159235596656799]\n"
          ]
        }
      ],
      "source": [
        "#########################  VARIABLES  ######################\n",
        "cell_no = 13\n",
        "Epoch_size = 50\n",
        "Lambda = 0.029  # dropout variable for regularization\n",
        "# No. of LSTM layers =2\n",
        "# Cost func. = cosh\n",
        "\n",
        "####################   MODEL STRUCTURE  ####################\n",
        "visible=Input(shape=(None,13))\n",
        "hidden11 = LSTM(cell_no,return_sequences=True)(visible)\n",
        "hidden1=Dropout(Lambda)(hidden11)\n",
        "\n",
        "hidden22 = LSTM(cell_no)(hidden1)\n",
        "hidden2=Dropout(Lambda)(hidden22)\n",
        "\n",
        "hidden33 = Dense(10, activation='relu')(hidden2)\n",
        "hidden3 = Dropout(Lambda)(hidden33)\n",
        "# hidden4 = TimeDistributed(Dense(1))\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(hidden3)\n",
        "# output=Dropout(Lambda)(output1)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "##################   MODEL END ########################\n",
        "count = 0\n",
        "for dr in dropouts:\n",
        "    total=0\n",
        "    for ii in range(1):\n",
        "        Lambda = dr\n",
        "        print(dr)\n",
        "\n",
        "        model.fit(x_train, y_train, epochs=Epoch_size, batch_size=10,verbose=1)\n",
        "        predict=model.predict(x_test)\n",
        "        y_pred=(predict>0.1)\n",
        "        acc=model.evaluate(x_test,y_test,verbose=0)\n",
        "        # print(predict)\n",
        "\n",
        "        total += acc[1]\n",
        "        print(acc)\n",
        "    total /=1\n",
        "    accuracy[count] = total\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "colab_type": "code",
        "id": "Z1WTvY0dyQHi",
        "outputId": "609008ca-38dc-4f8e-9abe-1b3a932d4a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, 13)]        0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, None, 13)          1404      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, None, 13)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 13)                1404      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 13)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                140       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,959\n",
            "Trainable params: 2,959\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Print f1, precision, and recall scores\n",
        "print(precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(f1_score(y_test, y_pred , average=\"macro\"))\n",
        "confusion = confusion_matrix(y_test,y_pred,labels=[0,1])\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "9qtXvBvWHt8a",
        "outputId": "7632fc5d-c7b3-4a10-c632-054b7a19fc34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.51592356])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "loVX2KG6zems"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Heart Sound Classification Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

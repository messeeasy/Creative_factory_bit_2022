{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "li7DvRTBW3D6"
      },
      "source": [
        "## **Installing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "colab_type": "code",
        "id": "JAGmKzcQvETi",
        "outputId": "22960d60-7d29-4d2d-8d7a-2ddb70d87fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.8/dist-packages (0.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gOD04lwoha8j"
      },
      "outputs": [],
      "source": [
        "#  os and argparse is done to read files from local folders\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "import scipy.signal\n",
        "from python_speech_features import mfcc\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "# tesorflow is for the Deep learning model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense ,LSTM , TimeDistributed\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "import IPython\n",
        "import librosa\n",
        "from scipy.signal import butter, lfilter\n",
        "%matplotlib inline\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "colab_type": "code",
        "id": "E6WKgvf-vCf4",
        "outputId": "7d80ee36-5be4-41d4-884f-ed066289e627"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive  # the sounds are stored in google drive \n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "8S1jwaxpvPQO",
        "outputId": "c199afdf-c1c7-43e0-8ab8-6880ea346fb4"
      },
      "outputs": [],
      "source": [
        "# folder where files are stored\n",
        "#cd /content/gdrive/'My Drive'/Colab Notebooks/data/training-a   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e0hJIGbCX002"
      },
      "source": [
        "**about the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "CRrgF44PvZxe",
        "outputId": "7636aaaa-2eb2-4afb-a468-a5fa60a53a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/python_env1/Creative_factory/Heart_sound_classification-master\n",
            "MFCC EXTRACTION DONE !\n"
          ]
        }
      ],
      "source": [
        "#############################################################  MFCC EXTRACTION   ##########################################################\n",
        "# Variable assignment \n",
        "tt = 0\n",
        "time_steps = 450\n",
        "data_directory=os.getcwd()\n",
        "print(data_directory)\n",
        "data_directory='/workspaces/python_env1/Creative_factory/the-circor-digiscope-phonocardiogram-dataset-1.0.3/AV'\n",
        "nfft = 1203 # Number of FFTs\n",
        "\n",
        "# What diff ?\n",
        "digit_directory = data_directory \n",
        "\n",
        "# To normalize the signal\n",
        "def normalize(v):\n",
        "    norm = np.linalg.norm(v)\n",
        "    if norm == 0: \n",
        "        return v\n",
        "    return v / norm\n",
        "    \n",
        "def process_directory():\n",
        "    mfcc_features = list()\n",
        "    \"\"\"\n",
        "    for filename in [x for x in os.listdir(data_directory) if x.endswith('.wav')]:\n",
        "        # Read the .wav input file\n",
        "        filepath = os.path.join(digit_directory, filename)\n",
        "        sampling_freq, audio = wavfile.read(filepath)\n",
        "        label=\"n.wav\"\n",
        "\n",
        "\n",
        "# open the .hea file of the same filename to get the label as normal /abnormal.\n",
        "        st= data_directory +\"/\"+filename.split(\".\")[0]+\".hea\"\n",
        "        with open(st,'r') as f:\n",
        "            for line in f:\n",
        "                for word in line.split():\n",
        "                    if(word==\"Abnormal\"):\n",
        "                        label=\"a.wav\"\n",
        "\"\"\"\n",
        "    #dataset = [{'sampling_freq', 'audio': wavfile.read(path) , 'label': path.split('/' )[6] } for path in glob.glob(\"/workspaces/python_env1/Creative_factory/the-circor-digiscope-phonocardiogram-dataset-1.0.3/AV/**/*.wav\")]\n",
        "    for path in glob.glob(\"/workspaces/python_env1/Creative_factory/the-circor-digiscope-phonocardiogram-dataset-1.0.3/AV/**/*.wav\"):\n",
        "        sampling_freq, audio = wavfile.read(path)\n",
        "        label = path.split('/')[6]\n",
        "            \n",
        "# now we have the label stored in 'label' and the audio as 'audio' with sampling freq. as 'sampling_freq'.\n",
        "        #audio1 = audio[dic[filename.split(\".\")[0]]:]\n",
        "        #audio1 = SVDnoise(audio/32768)\n",
        "        audio1 = audio\n",
        "        temp = mfcc(audio1, sampling_freq, nfft=nfft)\n",
        "        temp = temp[tt:tt+time_steps,:]\n",
        "        mfcc_features.append({\"label\": label, \"mfcc\": temp })\n",
        "\n",
        "\n",
        "        # mfcc features of this audio has been appended to the list \n",
        "    return mfcc_features\n",
        "\n",
        "###########################   CREATING MFCC FEATURES   ############################\n",
        "processed_files = list()\n",
        "mfcc_features = process_directory()\n",
        "random.shuffle(mfcc_features)\n",
        "\n",
        "############   TRAINING DATA   ###########\n",
        "size = (8*len(mfcc_features))/10\n",
        "train_features = mfcc_features[0:int(size)]\n",
        "test_list = mfcc_features[int(size+1):]\n",
        "train_size = 0\n",
        "for feature in train_features:\n",
        "    train_size += 1\n",
        "    processed_files.append({'label': feature[\"label\"], 'feature': feature[\"mfcc\"] })\n",
        "# Train rnn for each MFCC and add to training set\n",
        "x_train = np.zeros((train_size, time_steps ,13))\n",
        "y_train = np.zeros((train_size))\n",
        "i = 0\n",
        "for processed_file in processed_files:\n",
        "#       print(processed_file['label'])\n",
        "#       print(processed_file['feature'].shape)\n",
        "    x_train[i,:,:] = processed_file['feature']\n",
        "    s = processed_file['label']\n",
        "    if(s[0]=='a'):\n",
        "        y_train[i]=1\n",
        "    else:\n",
        "        y_train[i]=0\n",
        "    i += 1\n",
        "normalize(x_train)\n",
        "\n",
        "############   TESTING DATA   #############\n",
        "test_files = list()\n",
        "test_features = test_list\n",
        "test_size = 0\n",
        "for feature in test_features:\n",
        "    test_size += 1\n",
        "    test_files.append({'label': feature[\"label\"], 'feature': feature[\"mfcc\"] })\n",
        "y_test = np.zeros((test_size))\n",
        "x_test = np.zeros((test_size, time_steps ,13))\n",
        "i = 0\n",
        "for test_file in test_files:\n",
        "    x_test[i,:,:] = test_file['feature']\n",
        "    s = test_file['label']\n",
        "#             print(s)\n",
        "    if(s[0]=='a'):\n",
        "        y_test[i]=1\n",
        "    else:\n",
        "        y_test[i]=0\n",
        "    i += 1\n",
        "normalize(x_test)\n",
        "print('MFCC EXTRACTION DONE !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(629, 450, 13)\n",
            "(157, 450, 13)\n",
            "(629,)\n",
            "(157,)\n",
            "[0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
            " 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
            "80\n",
            "313\n",
            "787\n",
            "{'label': 'abnormal', 'mfcc': array([[ 15.46269988,   2.26491982, -21.26162075, ...,   6.94394165,\n",
            "          9.39867903,  -8.78965517],\n",
            "       [ 14.97789145,  -0.52184069, -15.22090411, ..., -10.92692502,\n",
            "         12.1397349 ,   3.37905973],\n",
            "       [ 14.92021627,   0.80159334,  -6.97476651, ..., -17.66333727,\n",
            "         11.0683195 ,   8.60210953],\n",
            "       ...,\n",
            "       [ 11.38392461,  -4.54423996,   0.33175843, ...,   1.76420096,\n",
            "          6.72300894,  -7.81671573],\n",
            "       [ 11.50086227,  -3.4872889 ,  -2.06473288, ...,   0.36976114,\n",
            "         11.11545633,  -0.88249009],\n",
            "       [ 11.43936274,  -2.57265147,  -2.96966   , ...,  -9.49272851,\n",
            "          6.79041415,   2.20170086]])}\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_test)\n",
        "print(np.count_nonzero(y_test == 0))\n",
        "print(np.count_nonzero(y_train == 0))\n",
        "print(len(mfcc_features))\n",
        "print(mfcc_features[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZaT_R-l04RW"
      },
      "source": [
        "## RNN MODEL\n",
        "### Model Structure:\n",
        "- visible layer or input layer : size of input = 13 (mfcc matrix has column size 13)\n",
        "- hidden layer 1: LSTM layer\n",
        "- hidden layer 2: LSTM layer\n",
        "- 1 dense layer having activation function = \"relu\" (rectified linear)\n",
        "- output layer : classification  \n",
        "\n",
        "![download.png](attachment:download.png)  \n",
        "<font size=\"2\">*In the figure, the dense layer is missing, but this is to give a brief idea of how the data is flowing in the model structure.*</font>  \n",
        "### Building the Model:\n",
        "- loss function: to compute the loss (currently \"mean squared error\")\n",
        "- optimizer function: adam\n",
        "- metrics: accuracy\n",
        "- **model.fit:** this function tries for the best possible fit of the model to the training data.\n",
        "<br>\n",
        "<font size=\"2\"> <font color=\"brown\"> The later part of the code was to try the model for different values of Dopout(lmabda) to calculate accuracy.</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RmDoZ-M-vZr_"
      },
      "outputs": [],
      "source": [
        "dropouts = np.array([0.15])\n",
        "accuracy = np.zeros(len(dropouts),dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "sMiXU1q1vZlt",
        "outputId": "2e53da3a-d7fe-4bf3-d914-1eec6ef3b2c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-18 17:06:46.998334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.013726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.014031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.014722: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-08-18 17:06:47.015114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.015386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.015637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.594869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.595160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.595403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-18 17:06:47.595617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6236 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-18 17:06:50.388475: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 4s 16ms/step - loss: 0.2500 - accuracy: 0.5008\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.2464 - accuracy: 0.5914\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.2418 - accuracy: 0.5962\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.2352 - accuracy: 0.6184\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.2259 - accuracy: 0.6455\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.2211 - accuracy: 0.6455\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.2122 - accuracy: 0.6773\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.2021 - accuracy: 0.7091\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.1890 - accuracy: 0.7393\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.1809 - accuracy: 0.7424\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1717 - accuracy: 0.7599\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1622 - accuracy: 0.7663\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1567 - accuracy: 0.7758\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.1485 - accuracy: 0.7981\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.1401 - accuracy: 0.8172\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.1334 - accuracy: 0.8267\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.1258 - accuracy: 0.8378\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.1226 - accuracy: 0.8458\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.1197 - accuracy: 0.8458\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.1084 - accuracy: 0.8665\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.1070 - accuracy: 0.8601\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1029 - accuracy: 0.8760\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0957 - accuracy: 0.8776\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.0986 - accuracy: 0.8792\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0942 - accuracy: 0.8855\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0915 - accuracy: 0.8744\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0719 - accuracy: 0.9221\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0693 - accuracy: 0.9189\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0634 - accuracy: 0.9332\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0610 - accuracy: 0.9285\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0646 - accuracy: 0.9300\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0667 - accuracy: 0.9205\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0581 - accuracy: 0.9285\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0549 - accuracy: 0.9412\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.0569 - accuracy: 0.9364\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0685 - accuracy: 0.9157\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.0637 - accuracy: 0.9253\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.0540 - accuracy: 0.9364\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.0458 - accuracy: 0.9523\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0492 - accuracy: 0.9428\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 1s 15ms/step - loss: 0.0473 - accuracy: 0.9444\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.0491 - accuracy: 0.9444\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.0439 - accuracy: 0.9555\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.0381 - accuracy: 0.9603\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0444 - accuracy: 0.9507\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.0393 - accuracy: 0.9587\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.0449 - accuracy: 0.9507\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0386 - accuracy: 0.9555\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.0417 - accuracy: 0.9539\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 1s 14ms/step - loss: 0.0427 - accuracy: 0.9539\n",
            "5/5 [==============================] - 0s 7ms/step\n",
            "[0.36484572291374207, 0.5732483863830566]\n"
          ]
        }
      ],
      "source": [
        "#########################  VARIABLES  ######################\n",
        "cell_no = 13\n",
        "Epoch_size = 50\n",
        "Lambda = 0.029  # dropout variable for regularization\n",
        "# No. of LSTM layers =2\n",
        "# Cost func. = cosh\n",
        "\n",
        "####################   MODEL STRUCTURE  ####################\n",
        "visible=Input(shape=(None,13))\n",
        "hidden11 = LSTM(cell_no,return_sequences=True)(visible)\n",
        "hidden1=Dropout(Lambda)(hidden11)\n",
        "\n",
        "hidden22 = LSTM(cell_no)(hidden1)\n",
        "hidden2=Dropout(Lambda)(hidden22)\n",
        "\n",
        "hidden33 = Dense(10, activation='relu')(hidden2)\n",
        "hidden3 = Dropout(Lambda)(hidden33)\n",
        "# hidden4 = TimeDistributed(Dense(1))\n",
        "\n",
        "output = Dense(1, activation='sigmoid')(hidden3)\n",
        "# output=Dropout(Lambda)(output1)\n",
        "\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "##################   MODEL END ########################\n",
        "count = 0\n",
        "for dr in dropouts:\n",
        "    total=0\n",
        "    for ii in range(1):\n",
        "        Lambda = dr\n",
        "        print(dr)\n",
        "\n",
        "        model.fit(x_train, y_train, epochs=Epoch_size, batch_size=10,verbose=1)\n",
        "        predict=model.predict(x_test)\n",
        "        y_pred=(predict>0.1)\n",
        "        acc=model.evaluate(x_test,y_test,verbose=0)\n",
        "        # print(predict)\n",
        "\n",
        "        total += acc[1]\n",
        "        print(acc)\n",
        "    total /=1\n",
        "    accuracy[count] = total\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "colab_type": "code",
        "id": "Z1WTvY0dyQHi",
        "outputId": "609008ca-38dc-4f8e-9abe-1b3a932d4a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5564276272306675\n",
            "0.5554383116883117\n",
            "0.5526701400195375\n",
            "[[39 41]\n",
            " [29 48]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Print f1, precision, and recall scores\n",
        "print(precision_score(y_test, y_pred , average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred , average=\"macro\"))\n",
        "print(f1_score(y_test, y_pred , average=\"macro\"))\n",
        "confusion = confusion_matrix(y_test,y_pred,labels=[0,1])\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "9qtXvBvWHt8a",
        "outputId": "7632fc5d-c7b3-4a10-c632-054b7a19fc34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.57324839])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "loVX2KG6zems"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Heart Sound Classification Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
